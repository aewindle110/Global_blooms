{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------\n",
    "# imports and initialization\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "import ee\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display,Image\n",
    "from helperFunctions import print_full\n",
    "from GEEimports import dumpclean # displays all levels of a json object\n",
    "from GEEimports import calcConsACCA,maskWater,calcGreenness\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# algorithms\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# Map bloom detection algorithm  over collection\n",
    "#  based on Ho et al. (2017) \"Using Landsat to extend historical phytoplankton bloom records\"\n",
    "def calcAlgorithms(img):\n",
    "#     # using the Landsat Automatic Cloud Cover Assessment \n",
    "#     img2 = calcConsACCA(img); \n",
    "#     yesCloud = img2.select(\"cloud\");\n",
    "    # using the FMask algorithm\n",
    "    yesCloud = img.select(['fmask']).eq(2).Or(img.select(['fmask']).eq(4));\n",
    "    img2 = img.addBands(yesCloud)\n",
    "    yesLand = img.select(['fmask']).eq(0).Or(img.select(['fmask']).eq(3));\n",
    "    \n",
    "    #Apply algorithms\n",
    "    img3=img2.expression(\"b('B4')-1.03*b('B5')\").select([\"B4\"],['ImpNIRwithSAC']);\n",
    "\n",
    "    #make negative values 0 \n",
    "    img3=img3.where(img3.lte(0),0);\n",
    "        \n",
    "    #use greenness threshold:\n",
    "    gness=calcGreenness(img);\n",
    "    img3=img3.where(gness.eq(0),0)\n",
    "    \n",
    "    #Mask clouds\n",
    "    img3=img3.updateMask(yesCloud.Not());\n",
    "    \n",
    "    return (img.addBands(img3)\n",
    "            .addBands(yesCloud.rename(['fmask_cloud']))\n",
    "            .addBands(yesLand.rename(['fmask_land']))\n",
    "            .addBands(img.select('fmask').eq(1).rename(['fmask_water']))\n",
    "           );\n",
    "    #add a constant image band so that later sum reducer gets\n",
    "    # total area of lakepolygon\n",
    "\n",
    "#Function to return a null feature with bloom area, used to get historical time series\n",
    "def calcBloom(img):  \n",
    "    #get the bands in image that you don't want masked by water\n",
    "    img_cloud = img.select('fmask_cloud');\n",
    "    img_cloud = img_cloud.updateMask(img_cloud);\n",
    "    img_land = img.select('fmask_land');\n",
    "    img_land = img_land.updateMask(img_land);\n",
    "    img_const = img.select('constant');\n",
    "    img_count = img.select('count');\n",
    "\n",
    "    #mask water in image\n",
    "    img = maskWater(img)\n",
    "\n",
    "    b = ee.Image(img.select('ImpNIRwithSAC')).reduceRegion(\n",
    "            reducer= ee.Reducer.sum(),\n",
    "            geometry=feat,       # NOTE THIS IS SET BEFOREHAND\n",
    "            scale=res,           # NOTE THIS IS SET BEFOREHAND\n",
    "            bestEffort=False,\n",
    "            maxPixels=15000000);\n",
    "    bloomSignal = ee.Number(b.get('ImpNIRwithSAC'))\n",
    "    m = ee.Dictionary({\n",
    "            'bloomSignal': bloomSignal\n",
    "        })\n",
    "    s = ee.Image(img.select(['ImpNIRwithSAC'])\n",
    "                 .addBands(img_cloud)\n",
    "                 .addBands(img_land)\n",
    "                 .addBands(img_const)\n",
    "                 .addBands(img_count)).reduceRegion(\n",
    "            reducer=ee.Reducer.count(),\n",
    "            geometry=feat,       # NOTE THIS IS SET BEFOREHAND\n",
    "            scale=res,           # NOTE THIS IS SET BEFOREHAND\n",
    "            bestEffort=False,\n",
    "            maxPixels=15000000);\n",
    "    \n",
    "    # max polygon area --> get from dictionary of largest polygon areas set ahead of time\n",
    "    px_max_poly = ee.Number(s.get('constant'));\n",
    "    # obs polygon area --> count in constant\n",
    "    px_obs_poly = ee.Number(s.get('count'));\n",
    "    # obs water area --> count in algorithm\n",
    "    px_obs_water = ee.Number(s.get('ImpNIRwithSAC'));\n",
    "    # obs land area --> count in land\n",
    "    px_obs_land = ee.Number(s.get('fmask_land'));\n",
    "    # obs cloud pixels --> count in cloud\n",
    "    px_obs_cloud = ee.Number(s.get('fmask_cloud'));\n",
    "    # valid pixels --> obs (cloud + water + land pixels)\n",
    "    featDict = m.combine(\n",
    "        ee.Dictionary({\n",
    "                'px_max_poly': px_max_poly,\n",
    "                'px_obs_poly': px_obs_poly,\n",
    "                'px_obs_water': px_obs_water,\n",
    "                'px_obs_land': px_obs_land,\n",
    "                'px_obs_cloud': px_obs_cloud,\n",
    "                'px_res': res,\n",
    "                'date': img.get('comp_mid'),\n",
    "                'comp_num_images': img.get('comp_num_images'),\n",
    "            })\n",
    "                        );\n",
    "    return ee.Feature(None, featDict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# meta parameters\n",
    "res = 30\n",
    "validation_regions = True\n",
    "exp_to_csv = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lake names in fc_shape (95):\n",
      "                          lakename\n",
      "0                            Abaya\n",
      "1                            Ai-pi\n",
      "2                           Alakol\n",
      "3                           Albert\n",
      "4                      Alexandrina\n",
      "5                         Aral-Sea\n",
      "6                        Argentina\n",
      "7                           Argyle\n",
      "8                          Ayakkum\n",
      "9                      Bahral-Milh\n",
      "10                    Baikal-North\n",
      "11                         Balaton\n",
      "12                        Balkhash\n",
      "13                     Barun-Torey\n",
      "14                             Bay\n",
      "15                          Beloye\n",
      "16                        Beysehir\n",
      "17                 BoengTonleChhma\n",
      "18                          Bosten\n",
      "19                       Bratskoye\n",
      "20                            Buyr\n",
      "21                     CaboraBassa\n",
      "22  Cha-jihNan-mu-tso--Zhari-Namco\n",
      "23                            Chao\n",
      "24                         Chapala\n",
      "25                  Chardarinskoye\n",
      "26                          Chilka\n",
      "27                        Chiquita\n",
      "28                          Chocon\n",
      "29                          Claire\n",
      "30                           Clear\n",
      "31                    Colhue-Huapi\n",
      "32                         Dauphin\n",
      "33                         Dubawnt\n",
      "34                          Edward\n",
      "35                     Erie-Center\n",
      "36                           Eyasi\n",
      "37                          Gaoyou\n",
      "38                      Great-Bear\n",
      "39                 Great-Salt-Lake\n",
      "40                         Gyaring\n",
      "41                             Har\n",
      "42                        Har-Hala\n",
      "43                           Harus\n",
      "44                          Hongze\n",
      "45                           Hulun\n",
      "46                       Itaparica\n",
      "47                          Izabal\n",
      "48                          Kainji\n",
      "49              KapchagayskoyeVodo\n",
      "50                          Kariba\n",
      "51                          Khanka\n",
      "52                 Kremenshugskoye\n",
      "53                   Kulundinskoye\n",
      "54                  Kuybyshevskoye\n",
      "55                           Labaz\n",
      "56                         Managua\n",
      "57                        Manitoba\n",
      "58                          Martre\n",
      "59                       Mono-Lake\n",
      "60                           Na-Mu\n",
      "61                          Nasser\n",
      "62                       Nerpichye\n",
      "63                       Nettiling\n",
      "64                         Ngoring\n",
      "65                       Nicaragua\n",
      "66                      Okeechobee\n",
      "67                       PeterPond\n",
      "68                           Poopo\n",
      "69                         Qinghai\n",
      "70                          Razelm\n",
      "71                           Rukwa\n",
      "72                     Saint-Clair\n",
      "73               Salton-Sea-Center\n",
      "74                 Sarykamyshskoye\n",
      "75                        Sasykkol\n",
      "76                          Se-lin\n",
      "77                    Selawik-Lake\n",
      "78                           Sevan\n",
      "79                          Simcoe\n",
      "80                   Songkhla-Lake\n",
      "81                           Taihu\n",
      "82                            Tana\n",
      "83                       Teshekpuk\n",
      "84                   Tsimlyanskoye\n",
      "85                         Turkana\n",
      "86                         Ulungar\n",
      "87                           Urmia\n",
      "88                        Victoria\n",
      "89                          Viedma\n",
      "90                     Walker-Lake\n",
      "91                       Winnebago\n",
      "92                        Winnipeg\n",
      "93                    Winnipegosis\n",
      "94                          Zaysan\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------\n",
    "# set up collections for algorithm application \n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# Import GLWD polygons (Lehner and Doll, 2004) that have been matched to \n",
    "#  GLTC lake information (Sharma 2015) and checked for validity:\n",
    "\n",
    "# Fusion Table with manually-corrected polygons: \"StudyLakePolygons_ManuallyCorrected\"\n",
    "# https://fusiontables.google.com/DataSource?docid=1pB9qGGnYixNVifTBIyEvgPpsMSqxPRT7dU-uwwrv\n",
    "fc_shape = ee.FeatureCollection( \n",
    "  \"ft:1pB9qGGnYixNVifTBIyEvgPpsMSqxPRT7dU-uwwrv\", \n",
    "  \"geometry\");\n",
    "# Fusion Table with lake auxiliary info: \"GLWD_join_GLTC\"\n",
    "# https://fusiontables.google.com/DataSource?docid=1EDVcrSyzzmInP7lbAb2FbJvoU9-UWMcnuYbnQuLt\n",
    "fc_meta = ee.FeatureCollection(\n",
    "  \"ft:1EDVcrSyzzmInP7lbAb2FbJvoU9-UWMcnuYbnQuLt\", \n",
    "  \"geometry\",)\n",
    "        \n",
    "# Prints all lake names in fc_shape\n",
    "pointList = fc_shape.toList(350).map(\n",
    "    lambda (f): ee.Feature(f).get(\"lakename\")\n",
    ");\n",
    "pointList_local = sorted(pointList.getInfo())\n",
    "print('Lake names in fc_shape (%s):' %len(pointList_local) )\n",
    "p=pd.DataFrame(pointList_local,columns=['lakename'])\n",
    "print_full(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = len(pointList_local);\n",
    "# original code loops through all 95 lakes above\n",
    "# for i in range(0, n): \n",
    "# This shows what the output looks like for Clear Lake\n",
    "for i in [30]:\n",
    "    try:\n",
    "        tic = time.time();\n",
    "        lakename = pointList_local[i]\n",
    "\n",
    "        # Get the lake polygon\n",
    "        print('Lake name: %s' % lakename)\n",
    "        lakerow_shape = fc_shape.filterMetadata('lakename', 'equals', lakename).first();\n",
    "\n",
    "        # Get the lake metadata\n",
    "        lakerow = fc_meta.filterMetadata('Lake_nam_1', 'equals', lakename.replace('-','.')).first(); \n",
    "        lakesize = lakerow.get('AREA_SKM').getInfo()\n",
    "        summer = lakerow.get('time_perio').getInfo()\n",
    "        # dumpclean(lakerow.getInfo()) #show metadata from this row\n",
    "\n",
    "        print('Lake is %s km^2' % lakesize)\n",
    "        # check which months are the summer months\n",
    "        if summer == 'JFM':\n",
    "            summer_months = [12,4]\n",
    "        elif summer == 'JAS':\n",
    "            summer_months = [6,10]\n",
    "        feat= lakerow_shape.geometry();\n",
    "\n",
    "        # get the overlapping summer LANDSAT image collection for lake polygon\n",
    "        L5_filt = ee.ImageCollection('LANDSAT/LT5_L1T_TOA_FMASK').filterBounds(feat).filter(\n",
    "            ee.Filter.calendarRange(summer_months[0],summer_months[1],'month'));\n",
    "\n",
    "        # apply algorithms\n",
    "        algName = ['ImpNIRwithSAC'];\n",
    "        L5_filt_alg = L5_filt.map(calcAlgorithms);\n",
    "\n",
    "        print ('Algorithms:')\n",
    "        print(algName)\n",
    "        print('...applied over Landsat 5 image collection.')\n",
    "\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "        # Get 15-day composites\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "\n",
    "        print('Generating 15-day composites...')\n",
    "\n",
    "        # a) Create a bunch of features for the time periods we want means for, \n",
    "        #   each with a dateRange property.  \n",
    "\n",
    "        #get list of dates for summer each year\n",
    "        dateList = [];\n",
    "        for yr in range(1984, 2012):\n",
    "            comp_start = ee.Date.fromYMD(yr,summer_months[0],1);\n",
    "            dateList.append(comp_start);\n",
    "            comp_end = ee.Date;\n",
    "            for i in range(1, 9):\n",
    "                comp_end = comp_start.advance(16,'day')\n",
    "                dateList.append(comp_end);\n",
    "                comp_start = comp_end;\n",
    "\n",
    "        dateRangeList = ee.List(dateList).map( \n",
    "            lambda (d): ee.DateRange(d,ee.Date(d).advance(16,'day'))\n",
    "        );\n",
    "\n",
    "        periods = dateRangeList.map(\n",
    "            lambda (dr): ee.Feature(None,{'daterange': dr})\n",
    "        );\n",
    "\n",
    "        # print('a) list of features with daterange propery:',periods.getInfo())\n",
    "\n",
    "        # b) SaveAll join those with the imagecollection (using dateRangeContains),\n",
    "\n",
    "        # Create a time filter to define a match as within daterange\n",
    "        periodFilter = ee.Filter.dateRangeContains(leftField='daterange',\n",
    "                                                   rightField='system:time_start'\n",
    "                                                  );\n",
    "\n",
    "        # Define the join.\n",
    "        saveAllJoin = ee.Join.saveAll(matchesKey='landsat',\n",
    "                                      ordering='system:time_start',\n",
    "                                      ascending=True,\n",
    "                                      measureKey='period'\n",
    "                                     );\n",
    "\n",
    "        # Apply the join.\n",
    "        landsatComp = saveAllJoin.apply(periods, L5_filt_alg, periodFilter);\n",
    "\n",
    "        # print('b) Join.saveAll:', landsatComp.getInfo());\n",
    "\n",
    "        # c) Map mean and set function over each of those, returning images.\n",
    "        \n",
    "        def getCompMean (feature1):\n",
    "            compCol = ee.ImageCollection.fromImages(feature1.get('landsat'));\n",
    "            compMean = compCol.mean(); #type: image\n",
    "\n",
    "            #adjust how fmask_cloud and fmask_land are treated when creating composites\n",
    "            compMean = compMean.select(ee.List(ee.Image(compMean).bandNames().remove('fmask_cloud')).remove('fmask_land'))\n",
    "            compMean = compMean.addBands(compCol.select(['fmask_cloud']).min())\n",
    "            compMean = compMean.addBands(compCol.select('fmask_land').max().where(compMean.select('fmask_water'),0))\n",
    "\n",
    "            compCount = compCol.select(['fmask']).count().rename(['count']); #type: image \n",
    "            compMean = compMean.set(\n",
    "                'comp_start',ee.DateRange(feature1.get('daterange')).start()).set(\n",
    "                'comp_mid',ee.DateRange(feature1.get('daterange')).start().advance(8,'day')).set(\n",
    "                'comp_end',ee.DateRange(feature1.get('daterange')).end()).set(\n",
    "                'comp_num_images',compCol.size());\n",
    "            return (compMean.addBands(compCount).addBands(ee.Image(1)));\n",
    "        \n",
    "        compMeans = ee.ImageCollection(landsatComp.map(getCompMean));\n",
    "        \n",
    "        # print('c) resultant imageCollection',compMeans.getInfo())\n",
    "\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "        # Statistics from composites\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "\n",
    "        # d) print dates from imageCollection to see which ranges were null\n",
    "\n",
    "        compDates = compMeans.toList(1000).map(\n",
    "            lambda (img): ee.Date(ee.Image(img).get('comp_mid')).format()\n",
    "        );\n",
    "        \n",
    "        # print('d) composite dates without nulls: ')\n",
    "        df = pd.DataFrame(compDates.getInfo(),columns=['date']);\n",
    "        # print(df)\n",
    "\n",
    "        compNums = compMeans.toList(1000).map(\n",
    "            lambda (img): ee.Image(img).get('comp_num_images')\n",
    "        );\n",
    "        # print('e) number of Images in each period:', compNums.getInfo())\n",
    "        \n",
    "        if validation_regions:\n",
    "             # Create historical image for validation\n",
    "            print('Creating historical mean image...')\n",
    "            compMeans_alg = compMeans.map(maskWater);\n",
    "            compMeans_alg = compMeans_alg.select('ImpNIRwithSAC');\n",
    "            histmean = compMeans_alg.mean()\n",
    "            exp_img = ee.Image(histmean).clip(feat);\n",
    "            exp_img_url = exp_img.getThumbURL(params={'min':0, 'max':0.01,'format':'png',\n",
    "                                               'palette':'000000,0000ff,00ffff,00ff00,ffff00,ffa500,ff0000',\n",
    "                                              }) \n",
    "\n",
    "            #visualize image in notebook\n",
    "            display(Image(url=exp_img_url))\n",
    "\n",
    "            #Import polygons for validation regions\n",
    "            # Fusion Table with regions: \"PolygonsForValidationRegions\"\n",
    "            # https://fusiontables.google.com/DataSource?docid=16V3xQruTtcugPsrSpRS8LuTglxxHbSw4fs834-XV\n",
    "            regions_all = ee.FeatureCollection(\n",
    "                \"ft:16V3xQruTtcugPsrSpRS8LuTglxxHbSw4fs834-XV\", \"geometry\")\n",
    "\n",
    "            # Get region_polys from fusion table\n",
    "            region = regions_all.filterMetadata('lakename', 'equals', lakename);\n",
    "            region_polys = region.toList(6).map( lambda(poly): ee.Feature(poly).get('region') )\n",
    "            print('List of regions:')\n",
    "            dumpclean(region_polys.getInfo())\n",
    "\n",
    "            # Get the mean of each region\n",
    "            num_region_polys = region_polys.length().getInfo();\n",
    "            print('Getting means of all {} regions'.format(num_region_polys))\n",
    "            histmean_regions = histmean.reduceRegions(region,ee.Reducer.mean(),res)\n",
    "\n",
    "            #start export process:\n",
    "            MyTry=ee.batch.Export.table(histmean_regions, \n",
    "                                        lakename+'_region_means_python',\n",
    "                                        {'fileFormat': 'CSV', 'driveFolder': 'GlobalBlooms'})\n",
    "            MyTry.start()\n",
    "            print('Export started:')\n",
    "            dumpclean(MyTry.status())\n",
    "            state = MyTry.status()['state']\n",
    "            while state in ['READY', 'RUNNING']:\n",
    "                print state + '...'\n",
    "                time.sleep(60)\n",
    "                state = MyTry.status()['state']\n",
    "            print 'Done.'\n",
    "            dumpclean(MyTry.status()) \n",
    "            print '------------------------------------------------------'\n",
    "        \n",
    "        elif exp_to_csv:\n",
    "\n",
    "            # Get means + other statistics\n",
    "            print('Getting csvs of means and other statistics...')\n",
    "\n",
    "            # Map reducer over composite images\n",
    "            stats = ee.FeatureCollection(compMeans.map(calcBloom));\n",
    "        #         print(stats.getInfo());\n",
    "\n",
    "            MyTry=ee.batch.Export.table(stats, lakename.replace('.','-')+'_15day_sum_ImpNIRwithSAC', \n",
    "                { 'fileFormat': 'CSV', 'driveFolder': 'GlobalBlooms'});\n",
    "            MyTry.start()\n",
    "            print('CSV export started:')\n",
    "            dumpclean(MyTry.status())\n",
    "            state = MyTry.status()['state']\n",
    "            while state in ['READY', 'RUNNING']:\n",
    "                print state + '...'\n",
    "                time.sleep(60)\n",
    "                state = MyTry.status()['state']\n",
    "            print 'CSV export finished.'\n",
    "            dumpclean(MyTry.status())\n",
    "            toc = time.time();\n",
    "            print 'Elapsed time: %s seconds' %(toc-tic)\n",
    "    except:\n",
    "        print \"Unexpected error:\", sys.exc_info()[0]\n",
    "        raise #stops loop on error, e.g., HTTP connection error\n",
    "\n",
    "print ('Done with all lakes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
